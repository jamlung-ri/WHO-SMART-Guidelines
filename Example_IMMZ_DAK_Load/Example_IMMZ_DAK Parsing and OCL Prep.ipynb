{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ad31284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Dos\n",
    "\n",
    "# - Make a special case for a library like Vaccine Library: This sheet should get a concept per row in the blue columns, plus a \"contains\"-like mapping for each code from each vocab\n",
    "# - Make value set with vaccine codes for Library\n",
    "\n",
    "# - Make value sets for all vaccine products\n",
    "\n",
    "# - Deal with duplicate input options? Or maybe just let OCL take the latest one?\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b2d9b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "environment = \"staging.\"\n",
    "ocl_org = \"WHO-Smart-Guidelines\"\n",
    "base_canonical_url = \"https://smart.who.int/smart-dak-example-immz/ValueSet/\"\n",
    "main_dak_source = 'smart-dak-example-immz'\n",
    "\n",
    "# Spreadsheet tab groups, which will be treated differently\n",
    "info_tabs = ['COVER','READ ME']  # Tabs with information only and should not be imported to OCL (leave empty if none are present)\n",
    "data_tabs = ['IMMZ.C Client Registration', 'IMMZ.D1 Capture client history', 'IMMZ.D Administer vaccine', 'IMMZ.I Report Generation']  # Tabs with DAK data for processing\n",
    "library_tab = 'IMMZ.Z Vaccine library'  # Tab containing Libraries of codes (leave blank if none is present)\n",
    "blue_columns = [\n",
    "    'Activity ID', 'Data Element ID', 'Data Element Label', 'Description and Definition',\n",
    "    'Multiple Choice Type \\n(if applicable)', 'Data Type', 'Input Options', 'Calculation',\n",
    "    'Quantity Sub-Type', 'Validation Condition', 'Editable', 'Required',\n",
    "    'Explain Conditionality', 'Linkages to Aggregate Indicators', 'Notes'\n",
    "] # These are columns with blue formatting, which are the primary concepts to be loaded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91d752fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Libraries to import\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import json\n",
    "import openpyxl\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "import re\n",
    "from tabulate import tabulate\n",
    "import unicodedata\n",
    "import csv\n",
    "\n",
    "\n",
    "\n",
    "# Suppress openpyxl warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='openpyxl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "468e873b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for better displaying larger tables\n",
    "def display_data_dict(data_dict):\n",
    "    for sheet_name, df in data_dict.items():\n",
    "        print(f\"\\n{sheet_name}:\")\n",
    "        print(tabulate(df, headers='keys', tablefmt='pipe', showindex=False))\n",
    "        print(f\"\\nShape: {df.shape}\")\n",
    "        print(\"-\" * 80)  # Separator between tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1aee53b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of processed sheets:\n",
      "Information sheets: ['COVER', 'READ ME']\n",
      "Data sheets: ['IMMZ.C Client Registration', 'IMMZ.D1 Capture client history', 'IMMZ.D Administer vaccine', 'IMMZ.I Report Generation']\n",
      "Library sheet: ['IMMZ.Z Vaccine library']\n"
     ]
    }
   ],
   "source": [
    "# Imports spreadsheet data\n",
    "\n",
    "# # Dataframe with sheet title and url from Google Sheets\n",
    "# urls_df = pd.DataFrame({\n",
    "#     'title': ['IMMZ.C Register Client', 'IMMZ.G Pre-vaccination Data', 'IMMZ.G Administer Vaccine', 'IMMZ.J Generate Reports', 'IMMZ.Z Vaccine Library'],\n",
    "#     'url': [\n",
    "#         'https://docs.google.com/spreadsheets/d/1cSPRs69VkkowMD6FQJ33l14dP70SfINP3st3p9eFuno/export?format=csv&id=1cSPRs69VkkowMD6FQJ33l14dP70SfINP3st3p9eFuno&gid=0',\n",
    "#         'https://docs.google.com/spreadsheets/d/1cSPRs69VkkowMD6FQJ33l14dP70SfINP3st3p9eFuno/export?format=csv&id=1cSPRs69VkkowMD6FQJ33l14dP70SfINP3st3p9eFuno&gid=536740205',\n",
    "#         'https://docs.google.com/spreadsheets/d/1cSPRs69VkkowMD6FQJ33l14dP70SfINP3st3p9eFuno/export?format=csv&id=1cSPRs69VkkowMD6FQJ33l14dP70SfINP3st3p9eFuno&gid=651729522',\n",
    "#         'https://docs.google.com/spreadsheets/d/1cSPRs69VkkowMD6FQJ33l14dP70SfINP3st3p9eFuno/export?format=csv&id=1cSPRs69VkkowMD6FQJ33l14dP70SfINP3st3p9eFuno&gid=1146884570',\n",
    "#         'https://docs.google.com/spreadsheets/d/1cSPRs69VkkowMD6FQJ33l14dP70SfINP3st3p9eFuno/export?format=csv&id=1cSPRs69VkkowMD6FQJ33l14dP70SfINP3st3p9eFuno&gid=975478021'\n",
    "#     ]\n",
    "# })\n",
    "\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# Specify the path to your Excel file\n",
    "excel_file_path = 'EXAMPLE IMMZ DAK_data dictionary.xlsx'\n",
    "\n",
    "# Load the Excel workbook\n",
    "workbook = openpyxl.load_workbook(excel_file_path, read_only=True)\n",
    "\n",
    "# Get all sheet names\n",
    "all_sheet_names = workbook.sheetnames\n",
    "\n",
    "# Create dictionaries to store DataFrames\n",
    "info_dict = {}\n",
    "data_dict = {}\n",
    "library_dict = {}\n",
    "\n",
    "# Read each sheet into the appropriate dictionary\n",
    "for sheet_name in all_sheet_names:\n",
    "    if sheet_name in info_tabs:\n",
    "        info_dict[sheet_name] = pd.read_excel(excel_file_path, sheet_name=sheet_name)\n",
    "    elif sheet_name in data_tabs:\n",
    "        data_dict[sheet_name] = pd.read_excel(excel_file_path, sheet_name=sheet_name)\n",
    "    elif sheet_name == library_tab:\n",
    "        library_dict[sheet_name] = pd.read_excel(excel_file_path, sheet_name=sheet_name)\n",
    "    else:\n",
    "        print(f\"Warning: Sheet '{sheet_name}' not categorized and will be skipped.\")\n",
    "\n",
    "# Close the workbook\n",
    "workbook.close()\n",
    "\n",
    "# Print summary\n",
    "print(\"\\nSummary of processed sheets:\")\n",
    "print(f\"Information sheets: {list(info_dict.keys())}\")\n",
    "print(f\"Data sheets: {list(data_dict.keys())}\")\n",
    "print(f\"Library sheet: {list(library_dict.keys())}\")\n",
    "\n",
    "# Now you can use info_dict, data_dict, and library_dict to access each sheet's data\n",
    "# For example:\n",
    "# info_data = info_dict['README']\n",
    "# client_data = data_dict['IMMZ.C Register Client']\n",
    "# library_data = library_dict['IMMZ.Z Vaccine Library']\n",
    "# display(library_dict['IMMZ.Z Vaccine library'])\n",
    "# display_data_dict(data_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f8c5f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Standardized column names:\n",
      "\n",
      "data_dict:\n",
      "\n",
      "  IMMZ.C Client Registration:\n",
      "  ['activity_id', 'data_element_id', 'data_element_label', 'description_and_definition', 'multiple_choice_type_if_applicable', 'data_type', 'input_options', 'calculation', 'quantity_subtype', 'validation_condition', 'editable', 'required', 'explain_conditionality', 'linkages_to_aggregate_indicators', 'notes', 'icd11code', 'icd11uri', 'icd11comments__considerations', 'icd11_relationship', 'icd10code', 'icd10comments__considerations', 'icd10_relationship', 'loinc_version_268code', 'loinc_version_268comments__considerations', 'loinc_version_268_relationship', 'ichi_beta_3code', 'ichiuri', 'ichicomments__considerations', 'ichi_relationship', 'icfcode', 'icfcomments__considerations', 'icf_relationship', 'snomed_gps_code', 'snomed_gps_comments__considerations', 'snomed_gpsrelationship']\n",
      "\n",
      "  IMMZ.D1 Capture client history:\n",
      "  ['activity_id', 'data_element_id', 'data_element_label', 'description_and_definition', 'relevant_antigens', 'multiple_choice_type_if_applicable', 'data_type', 'input_options', 'calculation', 'quantity_subtype', 'validation_condition', 'editable', 'required', 'explain_conditionality', 'linkages_to_aggregate_indicators', 'notes', 'icd11code', 'icd11uri', 'icd11comments__considerations', 'icd11_relationship', 'icd10code', 'icd10comments__considerations', 'icd10_relationship', 'loinc_version_268code', 'loinc_version_268comments__considerations', 'loinc_version_268_relationship', 'ichi_beta_3code', 'ichiuri', 'ichicomments__considerations', 'ichi_relationship', 'icfcode', 'icfcomments__considerations', 'icf_relationship', 'snomed_gps_code', 'snomed_gps_code_comments_considerations', 'snomed_gpsrelationship']\n",
      "\n",
      "  IMMZ.D Administer vaccine:\n",
      "  ['activity_id', 'data_element_id', 'data_element_label', 'description_and_definition', 'multiple_choice_type_if_applicable', 'data_type', 'input_options', 'calculation', 'quantity_subtype', 'validation_condition', 'editable', 'required', 'explain_conditionality', 'linkages_to_aggregate_indicators', 'notes', 'icd11code', 'icd11uri', 'icd11comments__considerations', 'icd11_relationship', 'icd10code', 'icd10comments__considerations', 'icd10_relationship', 'loinc_version_268code', 'loinc_version_268comments__considerations', 'loinc_version_269_relationship', 'ichi_beta_3code', 'ichiuri', 'ichicomments__considerations', 'ichi_relationship', 'icfcode', 'icfcomments__considerations', 'icf_relationship', 'snomed_gps_code', 'snomed_gps_code_comments__considerations', 'snomed_gpsrelationship']\n",
      "\n",
      "  IMMZ.I Report Generation:\n",
      "  ['activity_id', 'data_element_id', 'data_element_label', 'description_and_definition', 'multiple_choice_type_if_applicable', 'data_type', 'input_options', 'calculation', 'quantity_subtype', 'validation_condition', 'editable', 'required', 'explain_conditionality', 'linkages_to_aggregate_indicators', 'notes', 'icd11code', 'icd11uri', 'icd11comments__considerations', 'icd11_relationship', 'icd10code', 'icd10comments__considerations', 'icd10_relationship', 'loinc_version_268code', 'loinc_version_268comments__considerations', 'loinc_version_269_relationship', 'ichi_beta_3code', 'ichiuri', 'ichicomments__considerations', 'ichi_relationship', 'icfcode', 'icfcomments__considerations', 'icf_relationship', 'snomed_gps_code', 'snomed_gps_code_comments_considerations', 'snomed_gpsrelationship']\n",
      "\n",
      "library_dict:\n",
      "\n",
      "  IMMZ.Z Vaccine library:\n",
      "  ['activity_id', 'data_element_id', 'data_element_label', 'description_and_definition', 'multiple_choice_type_if_applicable', 'data_type', 'input_options', 'calculation', 'quantity_subtype', 'validation_condition', 'editable', 'required', 'explain_conditionality', 'linkages_to_aggregate_indicators', 'notes', 'icd11code', 'icd11uri', 'icd11comments__considerations', 'icd11_relationship', 'icd10code', 'icd10comments__considerations', 'icd10_relationship', 'loinc_version_268code', 'loinc_version_268comments__considerations', 'loinc_relationship', 'ichi_beta_3code', 'ichiuri', 'ichicomments__considerations', 'ichi_relationship', 'icfcode', 'icfcomments__considerations', 'icf_relationship', 'who_atc_code', 'who_atc_name', 'who_atc_relationship', 'snomed_gps_code', 'snomed_gps_codecomments__considerations', 'snomed_gps_relationship']\n",
      "\n",
      "Columns not present in all sheets:\n",
      "\n",
      "loinc_relationship:\n",
      "Present in: library_dict - IMMZ.Z Vaccine library\n",
      "Missing from: IMMZ.C Client Registration, IMMZ.D Administer vaccine, IMMZ.D1 Capture client history, IMMZ.I Report Generation, IMMZ.Z Vaccine library\n",
      "\n",
      "loinc_version_268_relationship:\n",
      "Present in: data_dict - IMMZ.C Client Registration, data_dict - IMMZ.D1 Capture client history\n",
      "Missing from: IMMZ.C Client Registration, IMMZ.D Administer vaccine, IMMZ.D1 Capture client history, IMMZ.I Report Generation, IMMZ.Z Vaccine library\n",
      "\n",
      "loinc_version_269_relationship:\n",
      "Present in: data_dict - IMMZ.D Administer vaccine, data_dict - IMMZ.I Report Generation\n",
      "Missing from: IMMZ.C Client Registration, IMMZ.D Administer vaccine, IMMZ.D1 Capture client history, IMMZ.I Report Generation, IMMZ.Z Vaccine library\n",
      "\n",
      "relevant_antigens:\n",
      "Present in: data_dict - IMMZ.D1 Capture client history\n",
      "Missing from: IMMZ.C Client Registration, IMMZ.D Administer vaccine, IMMZ.D1 Capture client history, IMMZ.I Report Generation, IMMZ.Z Vaccine library\n",
      "\n",
      "snomed_gps_code_comments__considerations:\n",
      "Present in: data_dict - IMMZ.D Administer vaccine\n",
      "Missing from: IMMZ.C Client Registration, IMMZ.D Administer vaccine, IMMZ.D1 Capture client history, IMMZ.I Report Generation, IMMZ.Z Vaccine library\n",
      "\n",
      "snomed_gps_code_comments_considerations:\n",
      "Present in: data_dict - IMMZ.D1 Capture client history, data_dict - IMMZ.I Report Generation\n",
      "Missing from: IMMZ.C Client Registration, IMMZ.D Administer vaccine, IMMZ.D1 Capture client history, IMMZ.I Report Generation, IMMZ.Z Vaccine library\n",
      "\n",
      "snomed_gps_codecomments__considerations:\n",
      "Present in: library_dict - IMMZ.Z Vaccine library\n",
      "Missing from: IMMZ.C Client Registration, IMMZ.D Administer vaccine, IMMZ.D1 Capture client history, IMMZ.I Report Generation, IMMZ.Z Vaccine library\n",
      "\n",
      "snomed_gps_comments__considerations:\n",
      "Present in: data_dict - IMMZ.C Client Registration\n",
      "Missing from: IMMZ.C Client Registration, IMMZ.D Administer vaccine, IMMZ.D1 Capture client history, IMMZ.I Report Generation, IMMZ.Z Vaccine library\n",
      "\n",
      "snomed_gps_relationship:\n",
      "Present in: library_dict - IMMZ.Z Vaccine library\n",
      "Missing from: IMMZ.C Client Registration, IMMZ.D Administer vaccine, IMMZ.D1 Capture client history, IMMZ.I Report Generation, IMMZ.Z Vaccine library\n",
      "\n",
      "snomed_gpsrelationship:\n",
      "Present in: data_dict - IMMZ.C Client Registration, data_dict - IMMZ.D Administer vaccine, data_dict - IMMZ.D1 Capture client history, data_dict - IMMZ.I Report Generation\n",
      "Missing from: IMMZ.C Client Registration, IMMZ.D Administer vaccine, IMMZ.D1 Capture client history, IMMZ.I Report Generation, IMMZ.Z Vaccine library\n",
      "\n",
      "who_atc_code:\n",
      "Present in: library_dict - IMMZ.Z Vaccine library\n",
      "Missing from: IMMZ.C Client Registration, IMMZ.D Administer vaccine, IMMZ.D1 Capture client history, IMMZ.I Report Generation, IMMZ.Z Vaccine library\n",
      "\n",
      "who_atc_name:\n",
      "Present in: library_dict - IMMZ.Z Vaccine library\n",
      "Missing from: IMMZ.C Client Registration, IMMZ.D Administer vaccine, IMMZ.D1 Capture client history, IMMZ.I Report Generation, IMMZ.Z Vaccine library\n",
      "\n",
      "who_atc_relationship:\n",
      "Present in: library_dict - IMMZ.Z Vaccine library\n",
      "Missing from: IMMZ.C Client Registration, IMMZ.D Administer vaccine, IMMZ.D1 Capture client history, IMMZ.I Report Generation, IMMZ.Z Vaccine library\n"
     ]
    }
   ],
   "source": [
    "# Standardize column names for standard data dictionary and library tabs - check this output for unexpected column names\n",
    "\n",
    "def standardize_column_names(data_dict):\n",
    "    standardized_dict = {}\n",
    "    for sheet_name, df in data_dict.items():\n",
    "        # Convert all column names to lowercase\n",
    "        df.columns = df.columns.str.lower()\n",
    "        # Replace spaces with underscores\n",
    "        df.columns = df.columns.str.replace(' ', '_')\n",
    "        # Remove any special characters (keep only alphanumeric and underscore)\n",
    "        df.columns = df.columns.str.replace(r'[^\\w]', '', regex=True)\n",
    "        standardized_dict[sheet_name] = df\n",
    "    return standardized_dict\n",
    "\n",
    "def standardize_column_name_list(column_names):\n",
    "    standardized_names = []\n",
    "    for name in column_names:\n",
    "        # Convert to lowercase\n",
    "        name = name.lower()\n",
    "        # Replace spaces with underscores\n",
    "        name = name.replace(' ', '_')\n",
    "        # Remove any special characters (keep only alphanumeric and underscore)\n",
    "        name = re.sub(r'[^\\w]', '', name)\n",
    "        standardized_names.append(name)\n",
    "    return standardized_names\n",
    "\n",
    "\n",
    "def compare_columns(standardized_dicts):\n",
    "    all_columns = set()\n",
    "    sheet_columns = {}\n",
    "    \n",
    "    # Collect all unique columns and columns for each sheet\n",
    "    for dict_name, dict_data in standardized_dicts.items():\n",
    "        for sheet_name, df in dict_data.items():\n",
    "            full_sheet_name = f\"{dict_name} - {sheet_name}\"\n",
    "            sheet_columns[full_sheet_name] = set(df.columns)\n",
    "            all_columns.update(df.columns)\n",
    "    \n",
    "    # Compare columns across sheets\n",
    "    column_presence = defaultdict(list)\n",
    "    for column in all_columns:\n",
    "        for full_sheet_name in sheet_columns.keys():\n",
    "            if column in sheet_columns[full_sheet_name]:\n",
    "                column_presence[column].append(full_sheet_name)\n",
    "    \n",
    "    # Identify columns not present in all sheets\n",
    "    all_sheets = set(sheet_columns.keys())\n",
    "    inconsistent_columns = {col: sheets for col, sheets in column_presence.items() if set(sheets) != all_sheets}\n",
    "    \n",
    "    return inconsistent_columns\n",
    "\n",
    "# Combine data_dict and library_dict\n",
    "all_dicts = {\n",
    "    'data_dict': data_dict,\n",
    "    'library_dict': library_dict\n",
    "}\n",
    "\n",
    "# Standardize column names for all dictionaries\n",
    "standardized_dicts = {dict_name: standardize_column_names(dict_data) for dict_name, dict_data in all_dicts.items()}\n",
    "\n",
    "# Compare columns across all sheets in all dictionaries\n",
    "inconsistent_columns = compare_columns(standardized_dicts)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nStandardized column names:\")\n",
    "for dict_name, dict_data in standardized_dicts.items():\n",
    "    print(f\"\\n{dict_name}:\")\n",
    "    for sheet_name, df in dict_data.items():\n",
    "        print(f\"\\n  {sheet_name}:\")\n",
    "        print(f\"  {df.columns.tolist()}\")\n",
    "\n",
    "print(\"\\nColumns not present in all sheets:\")\n",
    "for column in sorted(inconsistent_columns.keys()):  # Sort column names alphabetically\n",
    "    sheets = inconsistent_columns[column]\n",
    "    print(f\"\\n{column}:\")\n",
    "    print(f\"Present in: {', '.join(sorted(sheets))}\")  # Sort sheet names alphabetically\n",
    "    missing_sheets = set(sheet for dict_data in standardized_dicts.values() for sheet in dict_data.keys()) - set(sheets)\n",
    "    print(f\"Missing from: {', '.join(sorted(missing_sheets))}\")  # Sort missing sheet names alphabetically\n",
    "\n",
    "# Update the original dictionaries with standardized column names\n",
    "data_dict = standardized_dicts['data_dict']\n",
    "library_dict = standardized_dicts['library_dict']\n",
    "\n",
    "# # Data Checks\n",
    "# print(data_dict) # .to_csv('data_dict.csv', index=False, encoding='utf-8')\n",
    "# print(library_dict) # .to_csv('library_dict.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c58b8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section lists similar yet different column names, which were likely identified in the last code block. Place the 'correct' names on the right side of each dictionary.\n",
    "\n",
    "    # Mapping dictionaries for standardizing column names\n",
    "\n",
    "loinc_relationship_mapping = {\n",
    "    'loinc_relationship': 'loinc_relationship',\n",
    "    'loinc_version_268_relationship': 'loinc_relationship',\n",
    "    'loinc_version_269_relationship': 'loinc_relationship'\n",
    "}\n",
    "\n",
    "snomed_gps_comments_mapping = {\n",
    "    'snomed_gps_code_comments__considerations': 'snomed_gps_comments_considerations',\n",
    "    'snomed_gps_code_comments_considerations': 'snomed_gps_comments_considerations',\n",
    "    'snomed_gps_codecomments__considerations': 'snomed_gps_comments_considerations',\n",
    "    'snomed_gps_comments__considerations': 'snomed_gps_comments_considerations'\n",
    "}\n",
    "\n",
    "snomed_gps_relationship_mapping = {\n",
    "    'snomed_gps_relationship': 'snomed_gps_relationship',\n",
    "    'snomed_gpsrelationship': 'snomed_gps_relationship'\n",
    "}\n",
    "\n",
    "# Combine all mappings into a single dictionary\n",
    "column_name_mappings = {\n",
    "    **loinc_relationship_mapping,\n",
    "    **snomed_gps_comments_mapping,\n",
    "    **snomed_gps_relationship_mapping\n",
    "}\n",
    "\n",
    "# Additional columns that don't need mapping but should be included in the final set\n",
    "additional_columns = [\n",
    "    'relevant_antigens' #,\n",
    "    # 'who_atc_code',\n",
    "    # 'who_atc_name',\n",
    "    # 'who_atc_relationship'\n",
    "]\n",
    "\n",
    "\n",
    "def consolidate_column_names(columns):\n",
    "    return [column_name_mappings.get(col, col) for col in columns]\n",
    "# print(consolidate_column_names(library_dict['IMMZ.Z Vaccine library']))\n",
    "\n",
    "# Example usage:\n",
    "# consolidated_df = consolidate_column_names(original_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fddf3892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual columns in Library tab after consolidation:\n",
      "['activity_id', 'data_element_id', 'data_element_label', 'description_and_definition', 'multiple_choice_type_if_applicable', 'data_type', 'input_options', 'calculation', 'quantity_subtype', 'validation_condition', 'editable', 'required', 'explain_conditionality', 'linkages_to_aggregate_indicators', 'notes', 'icd11code', 'icd11uri', 'icd11comments__considerations', 'icd11_relationship', 'icd10code', 'icd10comments__considerations', 'icd10_relationship', 'loinc_version_268code', 'loinc_version_268comments__considerations', 'loinc_relationship', 'ichi_beta_3code', 'ichiuri', 'ichicomments__considerations', 'ichi_relationship', 'icfcode', 'icfcomments__considerations', 'icf_relationship', 'who_atc_code', 'who_atc_name', 'who_atc_relationship', 'snomed_gps_code', 'snomed_gps_comments_considerations', 'snomed_gps_relationship']\n",
      "Standardized and consolidated blue columns:\n",
      "['activity_id', 'data_element_id', 'data_element_label', 'description_and_definition', 'multiple_choice_type_if_applicable', 'data_type', 'input_options', 'calculation', 'quantity_subtype', 'validation_condition', 'editable', 'required', 'explain_conditionality', 'linkages_to_aggregate_indicators', 'notes']\n",
      "Available blue columns:\n",
      "['activity_id', 'data_element_id', 'data_element_label', 'description_and_definition', 'multiple_choice_type_if_applicable', 'data_type', 'input_options', 'calculation', 'quantity_subtype', 'validation_condition', 'editable', 'required', 'explain_conditionality', 'linkages_to_aggregate_indicators', 'notes']\n",
      "Rows in Library tab before filtering: 6\n",
      "Rows in Library tab after filtering: 1\n",
      "Common columns:\n",
      "['activity_id', 'data_element_id', 'data_element_label', 'description_and_definition', 'multiple_choice_type_if_applicable', 'data_type', 'input_options', 'calculation', 'quantity_subtype', 'validation_condition', 'editable', 'required', 'explain_conditionality', 'linkages_to_aggregate_indicators', 'notes']\n",
      "Added 1 rows from the Library tab to data_dict.\n",
      "\n",
      "Updated summary of data sheets:\n",
      "IMMZ.C Client Registration: 18 rows\n",
      "IMMZ.D1 Capture client history: 10 rows\n",
      "IMMZ.D Administer vaccine: 54 rows\n",
      "IMMZ.I Report Generation: 25 rows\n",
      "Processed Library Data: 1 rows\n"
     ]
    }
   ],
   "source": [
    "# Parse through Library tab, if available, to produce the concept(s) that will contain the mapped codes\n",
    "def standardize_column_name_list(column_names):\n",
    "    standardized_names = []\n",
    "    for name in column_names:\n",
    "        name = name.lower()\n",
    "        name = name.replace(' ', '_')\n",
    "        name = re.sub(r'[^\\w]', '', name)\n",
    "        standardized_names.append(name)\n",
    "    return standardized_names\n",
    "\n",
    "def process_library_tab(library_dict, data_dict):\n",
    "    if not library_dict:\n",
    "        print(\"No Library tab found. Skipping library processing.\")\n",
    "        return data_dict\n",
    "\n",
    "    library_df = library_dict[list(library_dict.keys())[0]]\n",
    "    \n",
    "    # Standardize and consolidate column names in library_df\n",
    "    library_df.columns = consolidate_column_names(standardize_column_name_list(library_df.columns))\n",
    "    \n",
    "    print(\"Actual columns in Library tab after consolidation:\")\n",
    "    print(library_df.columns.tolist())\n",
    "    \n",
    "    # Standardize and consolidate blue columns\n",
    "    standardized_blue_columns = consolidate_column_names(standardize_column_name_list(blue_columns))\n",
    "    print(\"Standardized and consolidated blue columns:\")\n",
    "    print(standardized_blue_columns)\n",
    "\n",
    "    # Filter the library DataFrame to include only blue columns that are present\n",
    "    available_blue_columns = [col for col in standardized_blue_columns if col in library_df.columns]\n",
    "    print(\"Available blue columns:\")\n",
    "    print(available_blue_columns)\n",
    "\n",
    "    if not available_blue_columns:\n",
    "        print(\"No blue columns found in the Library tab. Skipping processing.\")\n",
    "        return data_dict\n",
    "\n",
    "    library_df_blue = library_df[available_blue_columns]\n",
    "\n",
    "    print(f\"Rows in Library tab before filtering: {len(library_df)}\")\n",
    "    library_df_blue = library_df_blue.dropna(subset=available_blue_columns, how='all')\n",
    "    print(f\"Rows in Library tab after filtering: {len(library_df_blue)}\")\n",
    "\n",
    "    # Check if all columns in library_df_blue are present in data_dict\n",
    "    first_data_df = next(iter(data_dict.values()))\n",
    "    first_data_df.columns = consolidate_column_names(standardize_column_name_list(first_data_df.columns))\n",
    "\n",
    "    common_columns = [col for col in library_df_blue.columns if col in first_data_df.columns]\n",
    "    print(\"Common columns:\")\n",
    "    print(common_columns)\n",
    "\n",
    "    if not common_columns:\n",
    "        print(\"No common columns found between Library tab and data sheets. Skipping processing.\")\n",
    "        return data_dict\n",
    "\n",
    "    library_df_blue = library_df_blue[common_columns]\n",
    "\n",
    "    # Change \"data_type\" from \"Codes\" to \"Coding\"\n",
    "    if 'data_type' in library_df_blue.columns:\n",
    "        library_df_blue.loc[library_df_blue['data_type'] == 'Codes', 'data_type'] = 'Coding'\n",
    "\n",
    "    # Add the processed library data to data_dict\n",
    "    data_dict['Processed Library Data'] = library_df_blue\n",
    "\n",
    "    print(f\"Added {len(library_df_blue)} rows from the Library tab to data_dict.\")\n",
    "    return data_dict\n",
    "\n",
    "# Process the library tab and update data_dict\n",
    "data_dict = process_library_tab(library_dict, data_dict)\n",
    "\n",
    "# Print summary of data_dict after processing\n",
    "print(\"\\nUpdated summary of data sheets:\")\n",
    "for sheet_name, df in data_dict.items():\n",
    "    # Standardize and consolidate column names for each DataFrame in data_dict\n",
    "    df.columns = consolidate_column_names(standardize_column_name_list(df.columns))\n",
    "    print(f\"{sheet_name}: {len(df)} rows\")\n",
    "\n",
    "# Add this line to include additional columns\n",
    "for df in data_dict.values():\n",
    "    for col in additional_columns:\n",
    "        if col not in df.columns and col in library_dict[list(library_dict.keys())[0]].columns:\n",
    "            df[col] = library_dict[list(library_dict.keys())[0]][col]\n",
    "\n",
    "# Display the data_dict\n",
    "# print(data_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ef84e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all DataFrames\n",
    "df = pd.concat(data_dict.values(), keys=data_dict.keys(), verify_integrity=True)\n",
    "\n",
    "# Add source column indicating which DataFrame it came from\n",
    "df['Origin Tab'] = df.index.get_level_values(0)\n",
    "\n",
    "# Reset index to move source out of index\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Drop unnamed columns\n",
    "df = df.drop(columns=[col for col in df.columns if 'unnamed' in col.lower()])\n",
    "\n",
    "# Fix empty values\n",
    "df = df.fillna('')\n",
    "\n",
    "# Function to clean and normalize text\n",
    "def clean_text(text):\n",
    "    if isinstance(text, str):\n",
    "        # Replace specific problematic strings\n",
    "        text = text.replace('Date â‰¤ Current Date', 'Date ≤ Current Date')\n",
    "        # Replace other known problematic characters\n",
    "        text = text.replace('â€\"', '–')\n",
    "        # Remove other non-printable characters, but preserve '≤'\n",
    "        text = re.sub(r'[^\\x20-\\x7E\\n\\r\\t≤]', '', text)\n",
    "        # Strip leading and trailing spaces\n",
    "        text = text.strip()\n",
    "    return text\n",
    "\n",
    "# Apply cleaning function to all elements in the DataFrame\n",
    "df = df.applymap(clean_text)\n",
    "\n",
    "# Convert all data to strings after cleaning\n",
    "df = df.astype(str)\n",
    "\n",
    "# Combine duplicative columns (if they exist)\n",
    "if 'icd11comments__considerations' in df.columns and 'icd11comments__considerations1' in df.columns:\n",
    "    df['icd11comments__considerations'] = df.apply(\n",
    "        lambda row: row['icd11comments__considerations'] if row['icd11comments__considerations'] != '' and row['icd11comments__considerations1'] == ''\n",
    "        else row['icd11comments__considerations1'] if row['icd11comments__considerations'] == '' and row['icd11comments__considerations1'] != ''\n",
    "        else row['icd11comments__considerations'] if row['icd11comments__considerations'] == row['icd11comments__considerations1']\n",
    "        else row['icd11comments__considerations'] + '; ' + row['icd11comments__considerations1'],\n",
    "        axis=1\n",
    "    )\n",
    "    df.drop(columns='icd11comments__considerations1', inplace=True)\n",
    "\n",
    "# Fix unencoded values\n",
    "df = df.replace('–', '-', regex=True)\n",
    "\n",
    "# Export combined DataFrame to a CSV for data checking\n",
    "df.to_csv('combined.csv', index=False, encoding='utf-8')\n",
    "#display(df['validation_condition'][9])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b474973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming CSV for OCL import\n",
    "\n",
    "# Define a dictionary mapping old column names to new names\n",
    "# col_rename_map = {\n",
    "#   \"Activity ID\": \"attr:Activity_ID\",\n",
    "#   \"Data Element ID\": \"id\",\n",
    "#   \"Data Element Label\": \"name[1]\",\n",
    "#   \"Description and Definition\": \"description[1]\",\n",
    "#   \"Multiple Choice Type (if applicable)\": \"attr:Multiple_Choice_Type_(if_applicable)\",\n",
    "#   \"Data Type\": \"datatype\",\n",
    "#   \"Calculation\": \"attr:Calculation\",\n",
    "#   \"Quantity Sub-Type\": \"attr:Quantity_Sub-Type\",\n",
    "#   \"Validation Condition\": \"attr:Validation_Condition\",\n",
    "#   \"Editable\": \"attr:Editable\",\n",
    "#   \"Required\": \"attr:Required\",\n",
    "#   \"Skip Logic\": \"attr:Skip_Logic\",\n",
    "#   \"Linkages to Aggregate Indicators\": \"attr:Linkages_to_Aggregate_Indicators\",\n",
    "#   \"Notes\": \"attr:Notes\",\n",
    "#   \"ICD-11 URI\": \"attr:ICD-11_URI\",\n",
    "#   \"ICD-11 Comments / Considerations\": \"attr:ICD-11_Comments_Considerations\",\n",
    "#   \"ICD-11 Relationship\": \"map_type[0]\",\n",
    "#   \"ICD-10 Comments / Considerations\": \"attr:ICD-10_Comments_Considerations\",\n",
    "#   \"ICD-10 Relationship\": \"map_type[1]\",\n",
    "#   \"ICD-9 Comments / Considerations\": \"attr:ICD-9_Comments_Considerations\",\n",
    "#   \"ICD-9 Relationship\": \"map_type[2]\",\n",
    "#   \"LOINC version 2.68 Comments / Considerations\": \"attr:LOINC_version_2.68_Comments_Considerations\",\n",
    "#   \"LOINC version 2.68 Relationship\": \"map_type[3]\",\n",
    "#   \"ICHI URI\": \"attr:ICHI_URI\",\n",
    "#   \"ICHI Comments / Considerations\": \"attr:ICHI_Comments_Considerations\",\n",
    "#   \"ICHI Relationship\": \"map_type[4]\",\n",
    "#   \"ICF Comments / Considerations\": \"attr:ICF_Comments_Considerations\",\n",
    "#   \"ICF Relationship\": \"map_type[5]\",\n",
    "#   \"SNOMED GPS Code Comments Considerations\": \"attr:SNOMED_GPS_Code_Comments_Considerations\",\n",
    "#   \"SNOMED GPS Relationship\": \"map_type[6]\",\n",
    "#   \"SNOMED CT International Version Comments / Considerations\": \"attr:Snomed_CT_International_Version_Comments_Considerations\",\n",
    "#   \"SNOMED CT Relationship\": \"map_type[7]\",\n",
    "#   \"HL7 FHIR R4 - Resource\": \"attr:HL7_FHIR_R4_Resource\",\n",
    "#   \"HL7 FHIR R4 - Values\": \"attr:HL7_FHIR_R4_Values\",\n",
    "#   \"HL7 FHIR R4 Relationship\": \"map_type[8]\",\n",
    "#   \"ICD-11 Description\": \"attr:ICD-11_Description\",\n",
    "#   \"WHO ATC Name\": \"attr:WHO_ATC_Name\",\n",
    "#   \"Origin Tab\": \"attr:Activity_Group\",\n",
    "#   \"Input Options\": \"attr:Input_Options\",\n",
    "#   \"ICD-11 Code\": \"map_to_concept_url[0]\",\n",
    "#   \"ICD-10 Code\": \"map_to_concept_url[1]\",\n",
    "#   \"ICD-9 Code\": \"map_to_concept_url[2]\",\n",
    "#   \"LOINC version 2.68 Code\": \"map_to_concept_url[3]\",\n",
    "#   \"ICHI (Beta 3) Code\": \"map_to_concept_url[4]\",\n",
    "#   \"ICF Code\": \"map_to_concept_url[5]\",\n",
    "#   \"SNOMED GPS Code\": \"map_to_concept_url[6]\",\n",
    "#   \"SNOMED CT International Version Code\": \"map_to_concept_url[7]\",\n",
    "#   \"HL7 FHIR R4 Code\": \"map_to_concept_url[8]\",\n",
    "#   \"WHO ATC Code\": \"map_to_concept_url[9]\"\n",
    "# }\n",
    "\n",
    "col_rename_map = {\n",
    "    \"activity_id\": \"attr:Activity_ID\",\n",
    "    \"data_element_id\": \"id\",\n",
    "    \"data_element_label\": \"name[1]\",\n",
    "    \"description_and_definition\": \"description[1]\",\n",
    "    \"multiple_choice_type_if_applicable\": \"attr:Multiple_Choice_Type_(if_applicable)\",\n",
    "    \"data_type\": \"datatype\",\n",
    "    \"input_options\": \"attr:Input_Options\",\n",
    "    \"calculation\": \"attr:Calculation\",\n",
    "    \"quantity_subtype\": \"attr:Quantity_Sub-Type\",\n",
    "    \"validation_condition\": \"attr:Validation_Condition\",\n",
    "    \"editable\": \"attr:Editable\",\n",
    "    \"required\": \"attr:Required\",\n",
    "    \"explain_conditionality\": \"attr:Explain_Conditionality\",\n",
    "    \"linkages_to_aggregate_indicators\": \"attr:Linkages_to_Aggregate_Indicators\",\n",
    "    \"notes\": \"attr:Notes\",\n",
    "    \"icd11code\": \"map_to_concept_url[0]\",\n",
    "    \"icd11uri\": \"attr:ICD-11_URI\",\n",
    "    \"icd11comments__considerations\": \"attr:ICD-11_Comments_Considerations\",\n",
    "    \"icd11_relationship\": \"map_type[0]\",\n",
    "    \"icd10code\": \"map_to_concept_url[1]\",\n",
    "    \"icd10comments__considerations\": \"attr:ICD-10_Comments_Considerations\",\n",
    "    \"icd10_relationship\": \"map_type[1]\",\n",
    "    \"loinc_version_268code\": \"map_to_concept_url[3]\",\n",
    "    \"loinc_version_268comments__considerations\": \"attr:LOINC_version_2.68_Comments_Considerations\",\n",
    "    \"loinc_version_268_relationship\": \"map_type[3]\",\n",
    "    \"ichi_beta_3code\": \"map_to_concept_url[4]\",\n",
    "    \"ichiuri\": \"attr:ICHI_URI\",\n",
    "    \"ichicomments__considerations\": \"attr:ICHI_Comments_Considerations\",\n",
    "    \"ichi_relationship\": \"map_type[4]\",\n",
    "    \"icfcode\": \"map_to_concept_url[5]\",\n",
    "    \"icfcomments__considerations\": \"attr:ICF_Comments_Considerations\",\n",
    "    \"icf_relationship\": \"map_type[5]\",\n",
    "    \"snomed_gps_code\": \"map_to_concept_url[6]\",\n",
    "    \"snomed_gps_comments_considerations\": \"attr:SNOMED_GPS_Code_Comments_Considerations\",\n",
    "    \"snomed_gps_relationship\": \"map_type[6]\",\n",
    "    \"relevant_antigens\": \"attr:Relevant_Antigens\",\n",
    "    \"snomed_gps_code_comments_considerations\": \"attr:SNOMED_GPS_Code_Comments_Considerations\",\n",
    "    \"snomed_gps_code_comments__considerations\": \"attr:SNOMED_GPS_Code_Comments_Considerations\",\n",
    "    \"who_atc_code\":\"map_to_concept_url[9]\",\n",
    "    \"who_atc_name\":\"attr:WHO_ATC_Name\",\n",
    "    \"who_atc_relationship\":\"map_type[9]\",\n",
    "    \"Origin Tab\": \"attr:Activity_Group\"\n",
    "}\n",
    "\n",
    "# Rename columns using the mapping\n",
    "df = df.rename(columns=col_rename_map)\n",
    "\n",
    "# Set 'attr:Input_Options' to empty if same as 'Data Element ID'\n",
    "df['attr:Input_Options'] = df.apply(lambda row: '' if row['attr:Multiple_Choice_Type_(if_applicable)'] == \"Input Option\" else row['attr:Input_Options'], axis=1)\n",
    "#display(df)\n",
    "#df.to_csv('test.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2839c8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepping mappings for OCL CSV\n",
    "\n",
    "# Mapping prefixes (Column, prefix)\n",
    "prefix_dict = {\n",
    "  \"map_to_concept_url[0]\": \"/orgs/WHO/sources/ICD-11-WHO/concepts/\",\n",
    "  \"map_to_concept_url[1]\": \"/orgs/WHO/sources/ICD-10-WHO/concepts/\",\n",
    "  \"map_to_concept_url[2]\": \"/orgs/WHO/sources/ICD-9-WHO/concepts/\",\n",
    "  \"map_to_concept_url[3]\": \"/orgs/Regenstrief/sources/LOINC/concepts/\",\n",
    "  \"map_to_concept_url[4]\": \"/orgs/WHO/sources/WHO-ICHI/concepts/\",\n",
    "  \"map_to_concept_url[5]\": \"/orgs/WHO/sources/WHO-ICF/concepts/\",\n",
    "  \"map_to_concept_url[6]\": \"/orgs/SNOMED-International/sources/SNOMED-GPS/concepts/\",\n",
    "  \"map_to_concept_url[7]\": \"/orgs/IHTSDO/sources/SNOMED-CT/concepts/\",\n",
    "  \"map_to_concept_url[9]\": \"/orgs/WHO/sources/WHOATC/concepts/\"\n",
    "}\n",
    "\n",
    "# For each column col:\n",
    "#     It checks if the column exists in the DataFrame using if col in df.columns.\n",
    "#     If the column exists, it applies a lambda function to the column using df[col].apply(lambda x: ...).\n",
    "#     The lambda function checks if the string 'Not classifiable' is present in the value x. If it is, it replaces the value with an empty string ''.\n",
    "#     If 'Not classifiable' is not present, it splits the value x using the space character ' ' and takes the first part str(x).split(' ')[0].\n",
    "\n",
    "for col, prefix in prefix_dict.items():\n",
    "    # Check if column exists in the DataFrame\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].apply(lambda x: '' if 'Not classifiable' in str(x) else (prefix + str(x).split(' ')[0] if str(x) else ''))\n",
    "\n",
    "        # Convert map types to match OCL? Nah maybe later.\n",
    "        \n",
    "### Deal with HL7 codes to tie them to a code system\n",
    "\n",
    "# Dictionary with column value and system URL\n",
    "url_dict = {\n",
    "    \"male\": \"/orgs/HL7/sources/administrative-gender/\",\n",
    "    \"female\": \"/orgs/HL7/sources/administrative-gender/\",\n",
    "    \"other\": \"/orgs/HL7/sources/administrative-gender/\",\n",
    "    \"unknown\": \"/orgs/HL7/sources/administrative-gender/\",\n",
    "    \"http://hl7.org/fhir/uv/ips/ValueSet/vaccines-gps-uv-ips\": \"http://hl7.org/fhir/uv/ips/ValueSet/vaccines-gps-uv-ips\",\n",
    "    \"http://hl7.org/fhir/uv/ips/ValueSet/whoatc-uv-ips\": \"http://hl7.org/fhir/uv/ips/ValueSet/whoatc-uv-ips\",\n",
    "    \"http://hl7.org/fhir/ValueSet/immunization-route\": \"http://hl7.org/fhir/ValueSet/immunization-route\",\n",
    "    \"complete | pending | error\": \"https://build.fhir.org/valueset-measure-report-status.html\",\n",
    "    \"summary\": \"https://build.fhir.org/valueset-measure-report-type.html\",\n",
    "    \"increase\": \"/orgs/fhir-hl7-test/sources/measure-improvement-notation/\",\n",
    "    \"decrease\": \"/orgs/fhir-hl7-test/sources/measure-improvement-notation/\",\n",
    "    \"numerator\": \"/orgs/fhir-hl7-test/sources/measure-population/\",\n",
    "    \"denominator\": \"/orgs/fhir-hl7-test/sources/measure-population/\"\n",
    "}\n",
    "\n",
    "# # Update the column 'map_to_concept_url[8]'\n",
    "# df['map_to_concept_url[8]'] = df.apply(lambda row: '' if 'Not classifiable' in str(row['map_to_concept_url[8]']) else\n",
    "#                                       (url_dict.get(row['map_to_concept_url[8]'], '') + 'concepts/' + row['map_to_concept_url[8]']) if '/orgs/' in url_dict.get(row['map_to_concept_url[8]'], '') else\n",
    "#                                       url_dict.get(row['map_to_concept_url[8]'], ''), axis=1)\n",
    "\n",
    "# # Fixes blank map types for HL7 FHIR concepts and assigns them as \"Related to\"\n",
    "# df.loc[(df['map_to_concept_url[8]'] != '') & (df['map_type[8]'] == ''), 'map_type[8]'] = 'Related to'\n",
    "\n",
    "# # Create map_type[9] column based on map_to_concept_url[9]\n",
    "# map_to_col_9 = \"map_to_concept_url[9]\"\n",
    "# map_type_col_9 = \"map_type[9]\"\n",
    "\n",
    "# # Makes a mapping column for WHO ATC and sets them to \"Equivalent\" (which applies only to WHO ATC drug codes) \n",
    "# df[map_type_col_9] = \"\"\n",
    "# df.loc[df[map_to_col_9].notnull(), map_type_col_9] = \"Equivalent\"\n",
    "# display(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fd31fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Misc Cleanup\n",
    "# Function to check if a column exists\n",
    "def column_exists(df, column_name):\n",
    "    return column_name in df.columns\n",
    "\n",
    "# Function to add \"/\" to the end of non-blank values\n",
    "def add_trailing_slash(value):\n",
    "    if value and not value.endswith(\"/\"):\n",
    "        return value + \"/\"\n",
    "    return value\n",
    "\n",
    "# Assign Map Type if mapping is present\n",
    "# Iterate through each column of map_to_concept_url and map_type\n",
    "for i in range(10):\n",
    "    map_to_col = f\"map_to_concept_url[{i}]\"\n",
    "    map_type_col = f\"map_type[{i}]\"\n",
    "   \n",
    "    if column_exists(df, map_to_col) and column_exists(df, map_type_col):\n",
    "        # Update map_type based on map_to_concept_url\n",
    "        df.loc[(df[map_to_col] != '') & (df[map_type_col] == ''), map_type_col] = 'Unspecified map type'\n",
    "        \n",
    "        # Add \"/\" to the end of non-blank values in map_to_concept_url\n",
    "        df[map_to_col] = df[map_to_col].apply(add_trailing_slash)\n",
    "\n",
    "# Remove Map Type if no mapping is present  \n",
    "for i in range(10):\n",
    "    map_to_col = f\"map_to_concept_url[{i}]\"\n",
    "    map_type_col = f\"map_type[{i}]\"\n",
    "   \n",
    "    if column_exists(df, map_to_col) and column_exists(df, map_type_col):\n",
    "        df.loc[df[map_to_col].apply(lambda x: x.strip() == '') | df[map_to_col].isnull(), map_type_col] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bec7a337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create OCL-required columns that don't have special logic\n",
    "df['resource_type'] = 'Concept'\n",
    "df['source'] = main_dak_source\n",
    "df['owner_id'] = ocl_org\n",
    "df['owner_type'] = 'Organization'\n",
    "df['retired'] = 'FALSE'\n",
    "df['name_type[1]'] = 'Fully Specified'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "217ee723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relate input options back to their respective question\n",
    "df_inputs = df\n",
    "\n",
    "# Create new columns to store the mapping values and types\n",
    "df_inputs['map_from_concept_url[10]'] = np.nan\n",
    "df_inputs['map_to_concept_url[10]'] = np.nan\n",
    "df_inputs['map_type[10]'] = np.nan\n",
    "df_inputs['concept_class'] = np.nan\n",
    "\n",
    "# Initialize a variable to keep track of the last seen \"Coding\" row's id\n",
    "last_coding_id = None\n",
    "\n",
    "# Iterate through the dataframe\n",
    "for index, row in df_inputs.iterrows():\n",
    "    if row['datatype'] == 'Coding':\n",
    "        # Update the last seen \"Coding\" row's id\n",
    "        last_coding_id = row['id']\n",
    "    elif row['datatype'] == 'Codes' and pd.notna(last_coding_id):\n",
    "        # Only process 'Codes' rows when there's a previous 'Coding' row\n",
    "        df_inputs.at[index, 'map_type[10]'] = \"Q-AND-A\"\n",
    "        df_inputs.at[index, 'map_to_concept_url[10]'] = f\"/orgs/{row['owner_id']}/sources/{row['source']}/concepts/{row['id']}/\"\n",
    "        df_inputs.at[index, 'map_from_concept_url[10]'] = f\"/orgs/{row['owner_id']}/sources/{row['source']}/concepts/{last_coding_id}/\"\n",
    "        # df_inputs.at[index, 'concept_class'] = 'Input Option'\n",
    "\n",
    "# # Display the first few rows of the modified dataframe to verify the changes\n",
    "# print(df_inputs[['datatype', 'id', 'map_from_concept_url[10]', 'map_to_concept_url[10]', 'map_type[10]', 'concept_class']].head(20))\n",
    "\n",
    "# # Optional: Display summary of non-null values in each column\n",
    "# print(\"\\nCount of non-null values in each column:\")\n",
    "# print(df_inputs[['map_from_concept_url[10]', 'map_to_concept_url[10]', 'map_type[10]', 'concept_class']].notna().sum())\n",
    "\n",
    "# Display the first few rows of the modified dataframe to verify the changes\n",
    "# print(df_inputs[['datatype', 'id', 'map_from_concept_url[10]', 'map_type[10]', 'map_to_concept_url[10]']].head(10))\n",
    "\n",
    "    # Generate numerical IDs for rows without an existing 'id' value, if needed, then create Q-and-A mappings for those rows to connect them back to the data element (this step is dependent on spreadsheet order) \n",
    "# df_inputs.loc[df_inputs['id'] == '', 'id'] = range(1, 1 + len(df_inputs[df_inputs['id'] == '']))\n",
    "# df_inputs['map_to_concept_url[10]'] = \"/orgs/\" + df_inputs['owner_id'].astype(str) + \"/sources/\" + df_inputs['source'].astype(str) + \"/concepts/\" + df_inputs['id'].astype(str) + \"/\"\n",
    "# df_inputs['map_from_concept_url[10]'] = \"/orgs/\" + df_inputs['owner_id'].astype(str) + \"/sources/\" + df_inputs['source'].astype(str) + \"/concepts/\" + df_inputs['map_from_concept_url[10]'].replace('', method='ffill') + \"/\"\n",
    "# df_inputs.loc[df_inputs['map_from_concept_url[10]'] == \"/orgs/\" + df_inputs['owner_id'].astype(str) + \"/sources/\" + df_inputs['source'].astype(str) + \"/concepts/\" + df_inputs['id'].astype(str) + \"/\", ['map_type[10]', 'map_from_concept_url[10]', 'map_to_concept_url[10]']] = ''\n",
    "\n",
    "df_inputs['concept_class'] = df_inputs.apply(lambda x: 'Data Element' if x['map_type[10]'] != 'Q-AND-A' else 'Input Option', axis=1)\n",
    "\n",
    "# df_inputs.to_csv('test.csv', index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e1c8018",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Make df_v, which is a list of value sets (made of input options) to be loaded into OCL\n",
    "\n",
    "# Copies dataframe and subsets only to unique values that belong in valuesets\n",
    "df_v = df_inputs[df_inputs['map_from_concept_url[10]'] != ''].drop_duplicates(subset=['map_from_concept_url[10]']).copy()\n",
    "df_v = df_v[['map_from_concept_url[10]']].copy()\n",
    "df_v['id'] = df_v['map_from_concept_url[10]'].str.rsplit('/', n=2).str[-2]\n",
    "df_v['lookup'] = df_v['map_from_concept_url[10]'].str.rsplit('/', n=2).str[-2]\n",
    "\n",
    "# Drop rows where 'id' is NaN\n",
    "df_v = df_v.dropna(subset=['id'])\n",
    "\n",
    "df_v = df_v.drop_duplicates(subset='id').copy()\n",
    "\n",
    "\n",
    "# Merge the two dataframes based on the 'id' column\n",
    "merged_df = pd.merge(df_v, df_inputs, left_on='lookup', right_on='id', how='left')\n",
    "\n",
    "    # Access the value of the matching 'id' from the 'df_inputs' dataframe\n",
    "matching_value = merged_df['name[1]'].values[0]  # Retrieves the first matching value\n",
    "\n",
    "    # Keep only the specified columns and rename them\n",
    "merged_df = merged_df[['id_x', 'name[1]']].rename(columns={'id_x': 'id', 'name[1]': 'name'})\n",
    "\n",
    "# Change/update columns for Bulk Import\n",
    "merged_df['full_name'] = 'Values for: ' + merged_df['name']\n",
    "merged_df['owner'] = ocl_org\n",
    "merged_df['owner_type'] = \"Organization\"\n",
    "merged_df['default_locale'] = \"en\"\n",
    "merged_df['canonical_url'] = base_canonical_url + merged_df['id']\n",
    "merged_df['collection_type'] = \"Value Set\"\n",
    "merged_df['type'] = \"Collection\"\n",
    "merged_df['id'] = merged_df['id']+\"-values\"\n",
    "merged_df['name'] = merged_df['id']+\": \"+ merged_df['name']\n",
    "\n",
    "\n",
    "# Outputs the value sets to a JSON file\n",
    "with open('ocl-import-immz-value-sets.json', 'w') as outfile:\n",
    "    for index, row in merged_df.iterrows():\n",
    "        json.dump(row.to_dict(), outfile, ensure_ascii=False)\n",
    "        outfile.write('\\n')\n",
    "\n",
    "# Delete value sets if needed\n",
    "merged_df['__action'] = \"DELETE\"\n",
    "\n",
    "with open('delete-ocl-import-immz-value-sets.json', 'w') as outfile:\n",
    "    for index, row in merged_df.iterrows():\n",
    "        json.dump(row.to_dict(), outfile, ensure_ascii=False)\n",
    "        outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e5e8f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### To Do!\n",
    "### Makes value set list for Immunization Library\n",
    "\n",
    "# If there are NaN values, replace them with a suitable value\n",
    "df_inputs['id'] = df_inputs['id'].fillna('') # Replace NaN with an empty string\n",
    "    \n",
    "# df.head()\n",
    "# Filter the DataFrame to only include rows where the 'id' column starts with 'IMMZ.Z1'\n",
    "#filtered_df = df[df['id'].str.startswith('IMMZ.Z1')]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ba9371b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Adds ValueSet URL to df\n",
    "\n",
    "#Example: https://app.staging.openconceptlab.org/#/orgs/WHO-Smart-Guidelines/collections/IMMZ.E0.DE43-values/\n",
    "base_url = \"https://app.\"+environment+\"openconceptlab.org/#/orgs/WHO-Smart-Guidelines/collections/\"\n",
    "\n",
    "# Create a temporary DataFrame with only the 'id' column from merged_df\n",
    "temp_df = merged_df[['id']].copy()\n",
    "\n",
    "# Create a new 'matching_ID' column by removing \"-values\" from the 'id' column\n",
    "temp_df['matching_ID'] = temp_df['id'].str.replace('-values', '')\n",
    "\n",
    "# Merge df with temp_df on 'id' and 'matching_ID' to identify matching IDs\n",
    "merged_ids = df_inputs.merge(temp_df, left_on='id', right_on='matching_ID', how='inner')\n",
    "\n",
    "# Create 'attr:ValueSet_URL' column based on matching IDs\n",
    "df_inputs['attr:ValueSet_URL'] = df_inputs['id'].apply(lambda x: x + '-values' if x in merged_ids['matching_ID'].values else '')\n",
    "# Concatenate base_url to the existing values in 'attr:ValueSet_URL' column\n",
    "df_inputs['attr:ValueSet_URL'] = df_inputs.apply(lambda row: base_url + row['attr:ValueSet_URL'] if row['attr:ValueSet_URL'] else '', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c8efa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output as OCL-formatted CSV\n",
    "df_inputs.to_csv('ocl-import-dak.csv', index=False, encoding='utf-8')\n",
    "\n",
    "# Output test OCL file with only 10 rows\n",
    "#df.head(10).to_csv('SHORT - ocl-import-immz-dak.csv', index=False, encoding='utf-8')\n",
    "\n",
    "# Output value set list with only 10 rows (not needed now that it's in JSON format)\n",
    "#merged_df.head(10).to_csv('SHORT - ocl-import-immz-value-sets.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e4e1fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Makes df of references to import into the respective collections\n",
    "\n",
    "# Copies dataframe and subsets only to unique values that belong in valuesets\n",
    "df_ref = df_inputs[df_inputs['map_from_concept_url[10]'] != ''].drop_duplicates(subset=['map_from_concept_url[10]','map_to_concept_url[10]']).copy()\n",
    "df_ref = df_ref[['map_from_concept_url[10]','map_to_concept_url[10]']].copy()\n",
    "df_ref['col_id'] = df_ref['map_from_concept_url[10]'].str.rsplit('/', n=2).str[-2]+\"-values\"\n",
    "df_ref['collection_url'] = \"/orgs/\" + ocl_org +\"/collections/\" + df_ref['col_id'] + \"/\"\n",
    "\n",
    "# Drop rows where \"collection_url\" is NaN\n",
    "df_ref = df_ref.dropna(subset=['collection_url'])\n",
    "\n",
    "df_ref = df_ref[['collection_url', 'map_to_concept_url[10]']].rename(columns={'map_to_concept_url[10]': 'data:expressions'})\n",
    "df_ref[\"resource_type\"] = \"Reference\"\n",
    "\n",
    "#df_ref.head(10).to_csv('SHORT - ocl-import-immz-value-set-references.csv', index=False, encoding='utf-8')\n",
    "#display(df_ref)\n",
    "df_ref[\"type\"] = \"Reference\"\n",
    "output_json = df_ref.apply(lambda x: json.dumps({\"type\": x['type'], \"collection_url\": x['collection_url'], \"data\": {\"expressions\": [x['data:expressions']]}}), axis=1)\n",
    "\n",
    "# Print or save the JSON output\n",
    "# for item in output_json:\n",
    "#     print(item)\n",
    "\n",
    "#print(output_json)\n",
    "\n",
    "# Write the output to a JSON file\n",
    "with open(\"ocl-import-immz-value-set-references.json\", \"w\") as outfile:\n",
    "    for line in output_json:\n",
    "        outfile.write(line + '\\n')\n",
    "# Short JSON output\n",
    "# with open(\"SHORT - ocl-import-immz-value-set-references.json\", \"w\") as outfile:\n",
    "#     for line in output_json[:9]:\n",
    "#         outfile.write(line + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9d08af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Make df_vs_vers, which contains lines to create collection versions for the various value sets\n",
    "# Create a new DataFrame \"df_vs_vers\" with selected columns from \"merged_df\" and renamed column\n",
    "df_vs_vers = merged_df[['owner', 'id']].copy()\n",
    "df_vs_vers.rename(columns={'id': 'collection','owner': 'owner_id'}, inplace=True)\n",
    "\n",
    "# Add new columns \"resource_type\", \"id\", and \"description\" with specified values\n",
    "df_vs_vers['resource_type'] = 'Collection Version'\n",
    "df_vs_vers['id'] = '0.1.0'\n",
    "df_vs_vers['description'] = 'Initial Load'\n",
    "\n",
    "# Display the updated DataFrame \"df_vs_vers\"\n",
    "#print(df_vs_vers)\n",
    "\n",
    "#Output as CSV\n",
    "#df_vs_vers.to_json('ocl-import-immz-value-set-versions.json', orient='records', lines=True)\n",
    "df_vs_vers.to_csv('ocl-import-immz-value-set-versions.csv', index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
